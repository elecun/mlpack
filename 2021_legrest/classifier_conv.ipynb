{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "'''\n",
    "Hyper-parameters Settings\n",
    "'''\n",
    "HAMPEL_WINDOW_SIZE = 21\n",
    "HAMPEL_THRESHOLD = 1\n",
    "HAMPEL_IMPUTATION = True\n",
    "\n",
    "'''\n",
    "Path Settings\n",
    "'''\n",
    "CONFIGURATION_FILE_PATH = \"./data/train/data_config.csv\"\n",
    "DATASET_PATH = \"./data/train/\"\n",
    "\n",
    "'''\n",
    "Program Configurations\n",
    "'''\n",
    "COP_OUTPUT_SAVE_IMAGE = False\n",
    "COP_OUTPUT_SAVE_CSV = True\n",
    "LOADCELL_OUTPUT_SAVE_IMAGE = False\n",
    "LOADCELL_OUTPUT_SAVE_CSV = True\n",
    "FSR_SCALEUP_OUTPUT_SAVE_IMAGE = True\n",
    "FSR_SCALEUP_COMPARE_SAVE_IMAGE = False\n",
    "FSR_REGION_CROP_ENABLE = True\n",
    "DYNAMIC_FSR_SCALEUP = True\n",
    "\n",
    "\n",
    "'''\n",
    "Figure Settings\n",
    "'''\n",
    "pd.set_option('display.width', 200) # for display width\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Read Configurration File (only xls)\n",
    "'''\n",
    "data_config = pd.read_csv(CONFIGURATION_FILE_PATH, header=0, index_col=0)\n",
    "print(\"Configuration Dataframe dimension: \", data_config.shape)\n",
    "\n",
    "\n",
    "'''\n",
    "Read all FSR matrix data and Seat sensor data\n",
    "'''\n",
    "fsr_dataframe = {}\n",
    "seat_dataframe = {}\n",
    "\n",
    "for idx in data_config.index:\n",
    "    fsr_filepath = DATASET_PATH+data_config.loc[idx, \"fsr_matrix_1d_datafile\"] # set FSR matrix data filepath\n",
    "    seat_filepath = DATASET_PATH+data_config.loc[idx, \"seat_datafile\"] # set Seat data filepath\n",
    "    print(idx, \") read data files : \", fsr_filepath, \",\", seat_filepath)\n",
    "\n",
    "    fsr_dataframe[idx] = pd.read_csv(fsr_filepath, header=0, index_col=False).iloc[:,0:162] # read FSR matrix data file\n",
    "    seat_dataframe[idx] = pd.read_csv(seat_filepath, header=0, index_col=False) # read Seat data file\n",
    "\n",
    "    # clear unnecessary columns\n",
    "    del seat_dataframe[idx]['Measurement time'] # remove unnecessary column\n",
    "    del fsr_dataframe[idx]['Measurement Time (sec)'] # remove unnecessary column\n",
    "\n",
    "'''\n",
    "Preproceess : Data Segmentation by mtime\n",
    "   - @brief     FSR matrix data and Seat data should be segmented by mtime\n",
    "   - @output    segmented dataframes\n",
    "'''\n",
    "\n",
    "# output dict.\n",
    "fsr_dataframe_standard_segment = {}\n",
    "fsr_dataframe_relax_segment = {}\n",
    "seat_loadcell_dataframe_standard_segment = {}\n",
    "seat_loadcell_dataframe_relax_segment = {}\n",
    "\n",
    "\n",
    "for idx in data_config.index:\n",
    "    mtime = data_config.loc[idx, ['standard_s_mtime', \"standard_e_mtime\", \"relax_s_mtime\", \"relax_e_mtime\"]]\n",
    "\n",
    "    # seat loadcell segmentation\n",
    "    seat_loadcell_dataframe_standard_segment[idx] = seat_dataframe[idx][(seat_dataframe[idx]['mtime']>=mtime.standard_s_mtime) & (seat_dataframe[idx]['mtime']<=mtime.standard_e_mtime)]\n",
    "    seat_loadcell_dataframe_relax_segment[idx] = seat_dataframe[idx][(seat_dataframe[idx]['mtime']>=mtime.relax_s_mtime) & (seat_dataframe[idx]['mtime']<=mtime.relax_e_mtime)]\n",
    "\n",
    "    # fsr matrix segmentation\n",
    "    fsr_dataframe_standard_segment[idx] = fsr_dataframe[idx][(fsr_dataframe[idx]['mtime']>=mtime.standard_s_mtime) & (fsr_dataframe[idx]['mtime']<=mtime.standard_e_mtime)]\n",
    "    fsr_dataframe_relax_segment[idx] = fsr_dataframe[idx][(fsr_dataframe[idx]['mtime']>=mtime.relax_s_mtime) & (fsr_dataframe[idx]['mtime']<=mtime.relax_e_mtime)]\n",
    "\n",
    "    print(\"FSR Segments@Standard size : \", len(fsr_dataframe_standard_segment[idx]), \", FSR Segments@Relax size : \", len(fsr_dataframe_relax_segment[idx]))\n",
    "    print(\"Seat Segments@Standard size : \", len(seat_loadcell_dataframe_standard_segment[idx]), \", Seat Segments@Relax size : \", len(seat_loadcell_dataframe_relax_segment[idx]))\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Preproceess : Segmented FSR Matrix Data up-scaling\n",
    "   - @brief raw data(16x10 dim.) build high resolution image with interpolation(super-resolution)\n",
    "   - @method    catrom (Centripetal Catmullâ€“Rom spline)\n",
    "   - @output    scaled up images for all swquences\n",
    "   - @note  1) saving output image may take too long time. if you already done, skip this code block.\n",
    "            2) converting all data to image is not efficient. use start/end time configuration defined in data_config.csv\n",
    "            3) if file is already exist, process will be skiped.\n",
    "'''\n",
    "import os\n",
    "import os.path\n",
    "import gc\n",
    "from skimage import io, color\n",
    "\n",
    "\n",
    "if FSR_SCALEUP_OUTPUT_SAVE_IMAGE==True:\n",
    "    try:\n",
    "        os.mkdir(\"./images/fsr_matrix\") # create diretory\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "fsr_standard_interpolated_paths = {}\n",
    "fsr_relax_interpolated_paths = {}\n",
    "fsr_crop_standard_interpolated_paths = {}\n",
    "fsr_crop_relax_interpolated_paths = {}\n",
    "\n",
    "for idx in data_config.index:\n",
    "    fsr_standard_segment_1d = fsr_dataframe_standard_segment[idx].iloc[:,1:161]\n",
    "    fsr_standard_segment_2d = fsr_standard_segment_1d.values.reshape(-1, 16, 10) # reshape\n",
    "\n",
    "    fsr_relax_segment_1d = fsr_dataframe_relax_segment[idx].iloc[:,1:161]\n",
    "    fsr_relax_segment_2d = fsr_relax_segment_1d.values.reshape(-1, 16, 10)\n",
    "\n",
    "    try:\n",
    "        os.mkdir(\"./images/fsr_matrix/{}\".format(idx)) # create diretory for each id\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    # @standard mode\n",
    "    standard_fsr_file_list = []\n",
    "    standard_fsr_crop_file_list = []\n",
    "    for ridx in range(fsr_standard_segment_2d.shape[0]):\n",
    "        result_image_filepath = \"./images/fsr_matrix/{}/standard_{}.jpg\".format(idx, ridx)\n",
    "        result_crop_image_filepath = \"./images/fsr_matrix/{}/standard_crop_{}.jpg\".format(idx, ridx)\n",
    "\n",
    "        if FSR_SCALEUP_OUTPUT_SAVE_IMAGE==True:\n",
    "            if os.path.isfile(result_image_filepath)==True: # file exist\n",
    "                print(\"{} is already exist\".format(result_image_filepath))\n",
    "            else:\n",
    "                fig = plt.figure()\n",
    "                plt.axis('off')\n",
    "                if DYNAMIC_FSR_SCALEUP==True:\n",
    "                    plt.imshow(fsr_standard_segment_2d[ridx], interpolation='catrom', cmap='Greys_r')\n",
    "                else:\n",
    "                    plt.imshow(fsr_standard_segment_2d[ridx], interpolation='catrom', vmin=0, vmax=255, cmap='Greys_r')\n",
    "                plt.savefig(result_image_filepath, bbox_inches='tight', pad_inches=0)\n",
    "                plt.close(fig)\n",
    "\n",
    "            if FSR_REGION_CROP_ENABLE==True: # crop\n",
    "                if os.path.isfile(result_crop_image_filepath)==True: # file exist\n",
    "                    print(\"{} is already exist\".format(result_crop_image_filepath))\n",
    "                else:\n",
    "                    image = io.imread(result_image_filepath)\n",
    "                    grayscale = color.rgb2gray(image)\n",
    "                    crop = grayscale[0:grayscale.shape[0],int(grayscale.shape[1]/2):grayscale.shape[1]]\n",
    "                    io.imsave(result_crop_image_filepath, crop)\n",
    "                    print(\"crop image saved : {}\".format(result_crop_image_filepath))\n",
    "                    del image\n",
    "                standard_fsr_crop_file_list.append(result_crop_image_filepath)\n",
    "        \n",
    "        standard_fsr_file_list.append(result_image_filepath)\n",
    "        print(\"(standard) saved output images for id {}, {}\".format(idx, ridx))\n",
    "        \n",
    "    fsr_standard_interpolated_paths[idx] = pd.DataFrame(standard_fsr_file_list, columns=['path'])\n",
    "    fsr_crop_standard_interpolated_paths[idx] = pd.DataFrame(standard_fsr_crop_file_list, columns=['path'])\n",
    "    \n",
    "\n",
    "    # @ relax mode\n",
    "    relax_fsr_file_list = []\n",
    "    relax_fsr_crop_file_list = []\n",
    "    for ridx in range(fsr_relax_segment_2d.shape[0]):\n",
    "        result_image_filepath = \"./images/fsr_matrix/{}/relax_{}.jpg\".format(idx, ridx)\n",
    "        result_crop_image_filepath = \"./images/fsr_matrix/{}/relax_crop_{}.jpg\".format(idx, ridx)\n",
    "\n",
    "        if FSR_SCALEUP_OUTPUT_SAVE_IMAGE==True:\n",
    "            if os.path.isfile(result_image_filepath)==True: # file exist\n",
    "                print(\"{} is already exist\".format(result_image_filepath))\n",
    "            else:\n",
    "                fig = plt.figure()\n",
    "                plt.axis('off')\n",
    "                if DYNAMIC_FSR_SCALEUP==True:\n",
    "                    plt.imshow(fsr_relax_segment_2d[ridx], interpolation='catrom', cmap='Greys_r')\n",
    "                else:\n",
    "                    plt.imshow(fsr_relax_segment_2d[ridx], interpolation='catrom', vmin=0, vmax=255, cmap='Greys_r')\n",
    "                plt.savefig(result_image_filepath, bbox_inches='tight', pad_inches=0)\n",
    "                plt.close(fig)\n",
    "\n",
    "            if FSR_REGION_CROP_ENABLE==True: # crop\n",
    "                if os.path.isfile(result_crop_image_filepath)==True: # file exist\n",
    "                    print(\"{} is already exist\".format(result_crop_image_filepath))\n",
    "                else:\n",
    "                    image = io.imread(result_image_filepath)\n",
    "                    grayscale = color.rgb2gray(image)\n",
    "                    crop = grayscale[0:grayscale.shape[0],int(grayscale.shape[1]/2):grayscale.shape[1]]\n",
    "                    io.imsave(result_crop_image_filepath, crop)\n",
    "                    print(\"crop image saved : {}\".format(result_crop_image_filepath))\n",
    "                    del image\n",
    "                relax_fsr_crop_file_list.append(result_crop_image_filepath)\n",
    "        \n",
    "        relax_fsr_file_list.append(result_image_filepath)\n",
    "        print(\"(relax) saved output images for id {}, {}\".format(idx, ridx))\n",
    "        \n",
    "    fsr_relax_interpolated_paths[idx] = pd.DataFrame(relax_fsr_file_list, columns=['path'])\n",
    "    fsr_crop_relax_interpolated_paths[idx] = pd.DataFrame(relax_fsr_crop_file_list, columns=['path'])\n",
    "\n",
    "\n",
    "    if FSR_SCALEUP_COMPARE_SAVE_IMAGE==True:\n",
    "        # show compared graph between raw and upscaled data\n",
    "        # @ standard mode\n",
    "        for ridx in range(fsr_standard_segment_2d.shape[0]):\n",
    "\n",
    "            if DYNAMIC_FSR_SCALEUP==True:\n",
    "                result_image_filepath = \"./images/fsr_matrix/{}/compared_standard_dynamic_{}.png\".format(idx, ridx)\n",
    "            else:\n",
    "                result_image_filepath = \"./images/fsr_matrix/{}/compared_standard_static_{}.png\".format(idx, ridx)\n",
    "\n",
    "            # static interpolation\n",
    "            if os.path.isfile(result_image_filepath)==True: # file exist\n",
    "                print(\"{} is already exist\".format(result_image_filepath))\n",
    "            else:\n",
    "\n",
    "                fig = plt.figure(figsize=(11,6), constrained_layout=True)\n",
    "\n",
    "                # raw matrix data plot\n",
    "                fig_raw = fig.add_subplot(1,2,1)\n",
    "                if DYNAMIC_FSR_SCALEUP==True:\n",
    "                    ax_raw = fig_raw.imshow(fsr_standard_segment_2d[ridx], interpolation='None', cmap='viridis')\n",
    "                    fig_raw.set_title(\"Raw(Dynamic) FSR Matrix Data\", fontsize=16)\n",
    "                else:\n",
    "                    ax_raw = fig_raw.imshow(fsr_standard_segment_2d[ridx], interpolation='None', vmin=0, vmax=255, cmap='viridis')\n",
    "                    fig_raw.set_title(\"Raw(Static) FSR Matrix Data\", fontsize=16)\n",
    "                fig_raw.set_xlabel('X position(mm)')\n",
    "                fig_raw.set_ylabel('Y position(mm)')\n",
    "                fig.colorbar(ax_raw)\n",
    "\n",
    "                # interpolated matrix data plot\n",
    "                fig_hr = fig.add_subplot(1,2,2)\n",
    "                if DYNAMIC_FSR_SCALEUP==True:\n",
    "                    ax_hr = fig_hr.imshow(fsr_standard_segment_2d[ridx], interpolation='catrom', cmap='viridis')\n",
    "                    fig_hr.set_title(\"Interpolated(Dynamic) FSR Matrix Data\", fontsize=16)\n",
    "                else:\n",
    "                    ax_hr = fig_hr.imshow(fsr_standard_segment_2d[ridx], interpolation='catrom', vmin=0, vmax=255, cmap='viridis')\n",
    "                    fig_hr.set_title(\"Interpolated(Static) FSR Matrix Data\", fontsize=16)\n",
    "                \n",
    "                fig_hr.set_xlabel('X position(mm)')\n",
    "                fig_hr.set_ylabel('Y position(mm)')\n",
    "                fig.colorbar(ax_hr)\n",
    "            \n",
    "                fig.savefig(result_image_filepath)\n",
    "                print(\"(standard) save to image : \",result_image_filepath)\n",
    "                plt.close(fig)\n",
    "\n",
    "        # @relax mode\n",
    "        for ridx in range(fsr_relax_segment_2d.shape[0]):\n",
    "            # save to image file\n",
    "            if DYNAMIC_FSR_SCALEUP==True:\n",
    "                result_image_filepath = \"./images/fsr_matrix/{}/compared_relax_dynamic_{}.png\".format(idx, ridx)\n",
    "            else:\n",
    "                result_image_filepath = \"./images/fsr_matrix/{}/compared_relax_static_{}.png\".format(idx, ridx)\n",
    "\n",
    "            if os.path.isfile(result_image_filepath)==True: # file exist\n",
    "                print(\"{} is already exist\".format(result_image_filepath))\n",
    "            else:\n",
    "\n",
    "                fig = plt.figure(figsize=(11,6), constrained_layout=True)\n",
    "\n",
    "                # raw matrix data plot\n",
    "                fig_raw = fig.add_subplot(1,2,1)\n",
    "                if DYNAMIC_FSR_SCALEUP==True:\n",
    "                    ax_raw = fig_raw.imshow(fsr_relax_segment_2d[ridx], interpolation='None', cmap='viridis')\n",
    "                    fig_raw.set_title(\"Raw(Dynamic) FSR Matrix Data\", fontsize=16)\n",
    "                else:\n",
    "                    ax_raw = fig_raw.imshow(fsr_relax_segment_2d[ridx], interpolation='None', vmin=0, vmax=255, cmap='viridis')\n",
    "                    fig_raw.set_title(\"Raw(Static) FSR Matrix Data\", fontsize=16)\n",
    "                fig_raw.set_xlabel('X position(mm)')\n",
    "                fig_raw.set_ylabel('Y position(mm)')\n",
    "                fig.colorbar(ax_raw)\n",
    "\n",
    "                # interpolated matrix data plot\n",
    "                fig_hr = fig.add_subplot(1,2,2)\n",
    "                if DYNAMIC_FSR_SCALEUP==True:\n",
    "                    ax_hr = fig_hr.imshow(fsr_relax_segment_2d[ridx], interpolation='catrom', cmap='viridis')\n",
    "                    fig_hr.set_title(\"Interpolated(Dynamic) FSR Matrix Data\", fontsize=16)\n",
    "                else:\n",
    "                    ax_hr = fig_hr.imshow(fsr_relax_segment_2d[ridx], interpolation='catrom', vmin=0, vmax=255, cmap='viridis')\n",
    "                    fig_hr.set_title(\"Interpolated(Static) FSR Matrix Data\", fontsize=16)\n",
    "                fig_hr.set_xlabel('X position(mm)')\n",
    "                fig_hr.set_ylabel('Y position(mm)')\n",
    "                fig.colorbar(ax_hr) \n",
    "            \n",
    "                fig.savefig(result_image_filepath)\n",
    "                print(\"(relax) save to image : \",result_image_filepath)\n",
    "                plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Model Training\n",
    "@brief  Multiclass Classification using CONV+GRU with keras\n",
    "'''\n",
    "import random\n",
    "\n",
    "# class separation (positive, negative)\n",
    "shuffled_index = np.array(data_config.index)\n",
    "random.shuffle(shuffled_index)\n",
    "positive_class = shuffled_index[0:5] # first 5 index select from shuffled_index\n",
    "negative_class = shuffled_index[5:]\n",
    "negative_class_zero = np.zeros(len(negative_class), dtype=int)\n",
    "classes = np.append(positive_class, 0)\n",
    "\n",
    "# 1. input image transfer into the convolution network\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras_video import VideoFrameGenerator\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# user parameters\n",
    "SIZE = (68, 217) # crop image\n",
    "CHANNELS = 3 # image channels\n",
    "NBFRAME = 5 # near frames\n",
    "BS = 10 #batch size\n",
    "KERNEL_SIZE = (3,3)\n",
    "EPOCHS=20\n",
    "\n",
    "def build_convnet(shape=(SIZE, CHANNELS)):\n",
    "    momentum = 0.9\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(64, KERNEL_SIZE, input_shape=shape, padding='same', activation='relu')) # shape = (row, col, channels)\n",
    "    model.add(Conv2D(64, KERNEL_SIZE, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(128, KERNEL_SIZE, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, KERNEL_SIZE, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(256, KERNEL_SIZE, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, KERNEL_SIZE, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(512, KERNEL_SIZE, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, KERNEL_SIZE, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    # flatten\n",
    "    model.add(GlobalMaxPool2D())\n",
    "    return model\n",
    "\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout, LSTM\n",
    "\n",
    "def action_model(shape=(SIZE, CHANNELS), nbout=5):\n",
    "    #create convnet with (112, 112, 1) input shape\n",
    "    convnet = build_convnet(shape[1:])\n",
    "\n",
    "    #then create out final model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # add the convnet with (5, 112, 112, 3) shape\n",
    "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
    "\n",
    "    # you can also use GRU or LSTM\n",
    "    model.add(GRU(5))\n",
    "\n",
    "    # finally we make a decision network\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# model compile\n",
    "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,)\n",
    "print(INSHAPE)\n",
    "model = action_model(INSHAPE, len(classes))\n",
    "#optimizer = keras.optimizers.Adam(0.001)\n",
    "optimizer = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    'categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "# use sub directories names as classes\n",
    "classes = [i.split(os.path.sep)[1] for i in glob.glob('train/*')]\n",
    "classes.sort()\n",
    "\n",
    "# pattern to get videos and classes\n",
    "glob_pattern='train/{classname}/standard_*.avi'\n",
    "# for data augmentation\n",
    "# data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "#     zoom_range=.1,\n",
    "#     horizontal_flip=False,\n",
    "#     rotation_range=8,\n",
    "#     width_shift_range=.2,\n",
    "#     height_shift_range=.2)\n",
    "\n",
    "# Create video frame generator\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    split_val=.2, \n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    #transformation=data_aug,\n",
    "    use_frame_cache=False)\n",
    "\n",
    "\n",
    "valid = train.get_validation_generator()\n",
    "print(valid)\n",
    "\n",
    "# create a \"chkp\" directory before to run that\n",
    "# because ModelCheckpoint will write models inside\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ]
}