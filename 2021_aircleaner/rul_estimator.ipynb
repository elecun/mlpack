{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUL Indication : 23.7868047294905% (237868.047294905/1000000)\n"
     ]
    }
   ],
   "source": [
    "from curses import meta\n",
    "from typing_extensions import Self\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateutil.parser as dp\n",
    "from datetime import datetime as dt\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from abc import ABCMeta, abstractmethod\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import sympy as sy\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "'''\n",
    "Abstract Class for Estimator\n",
    "'''\n",
    "class estimator(metaclass=ABCMeta):\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimate(self, data:pd.DataFrame) -> np.double:\n",
    "        pass\n",
    "\n",
    "'''\n",
    "Air Cleaner Filter RUL Estimator\n",
    "'''\n",
    "class filterRUL(estimator):\n",
    "    def __init__(self, life:int, model:str) -> None:\n",
    "\n",
    "        '''\n",
    "        Hyper-parameters & Custom parameters\n",
    "        '''\n",
    "        self._max_lifetime = life    # Maximum Filter Lifetime\n",
    "        self._outcabin_mean = 67.24013933547695 # should be changed\n",
    "        self._outcabin_std = 54.32043175206877 # should be changed\n",
    "        self._inflow_cutoff = 70\n",
    "        self._ols_dt_min = 10\n",
    "\n",
    "        if model is None:\n",
    "            self.model = pickle.load(open('knn_outcabin', 'rb'))\n",
    "        else:\n",
    "            self.model = pickle.load(open(model, 'rb'))\n",
    "\n",
    "    def estimate(self, data:pd.DataFrame, start_date:str, end_date:str) -> dict:\n",
    "\n",
    "        # 1. estimate outcabin pm2.5\n",
    "        input = data.dropna()[\"airkorea_pm25_z_filtered\"]\n",
    "        outcabin_pm25 = self.model.predict(input.to_numpy().reshape(-1,1))\n",
    "\n",
    "        # 2. z-score reverse (for outcabin pm2.5)\n",
    "        outcabin_pm25_list = outcabin_pm25.reshape(-1).tolist()\n",
    "        data[\"auton_outcabin_pm25_z\"] = pd.Series(outcabin_pm25_list, index=input.index)\n",
    "        data[\"auton_outcabin_pm25\"] = data[\"auton_outcabin_pm25_z\"]*self._outcabin_std+self._outcabin_mean\n",
    "\n",
    "        # 3. pm2.5 concentration flows into the in-cabin\n",
    "        data[\"auton_inflow_pm25\"] = data[\"auton_outcabin_pm25\"]*(1-self._inflow_cutoff/100)\n",
    "\n",
    "        # 4. RUL condition indication with OLS\n",
    "        t_data = data[[\"date\", 'auton_inflow_pm25', 'auton_incabin_pm25']]\n",
    "        t_range = pd.date_range(start=start_date, end=end_date, freq='{}min'.format(self._ols_dt_min))\n",
    "\n",
    "        \n",
    "        stack = {}\n",
    "        for start_date in t_range.to_list():\n",
    "            end_date = start_date + timedelta(minutes=self._ols_dt_min)\n",
    "            mask = (t_data['date'] > start_date) & (t_data['date'] <= end_date)\n",
    "\n",
    "            t_sliced = t_data.loc[mask][['date', 'auton_inflow_pm25', 'auton_incabin_pm25']]\n",
    "\n",
    "            if t_sliced.dropna().empty is False:\n",
    "\n",
    "                y1_data = t_sliced['auton_inflow_pm25']\n",
    "                y2_data = t_sliced['auton_incabin_pm25']\n",
    "                x_data = t_sliced.index\n",
    "\n",
    "                mask_1 = ~np.isnan(x_data) & ~np.isnan(y1_data)\n",
    "                mask_2 = ~np.isnan(x_data) & ~np.isnan(y2_data)\n",
    "                res_1 = stats.linregress(x_data[mask_1], y1_data[mask_1])\n",
    "                res_2 = stats.linregress(x_data[mask_2], y2_data[mask_2])\n",
    "\n",
    "                def g(x):\n",
    "                    return res_1.slope*x+res_1.intercept\n",
    "                def u(x):\n",
    "                    return res_2.slope*x+res_2.intercept\n",
    "\n",
    "                x = sy.Symbol('x')\n",
    "                area = sy.integrate(g(x) - u(x), (x, x_data.min(), x_data.max()))\n",
    "                if area != sy.nan:\n",
    "                    stack[start_date] = area\n",
    "                \n",
    "        stack_area = pd.DataFrame(data=list(stack.items()), columns=['date', 'area'])\n",
    "        cumsum = stack_area[\"area\"].dropna().cumsum(axis=0)\n",
    "\n",
    "        result = {}\n",
    "        result[\"max_life\"] = self._max_lifetime\n",
    "        result[\"rul\"] = cumsum.values[-1]\n",
    "        return result\n",
    "\n",
    "\n",
    "'''\n",
    "Load data form file\n",
    "'''\n",
    "def loaddata_from_file(filepath:str) -> pd.DataFrame:\n",
    "\n",
    "    # 1. load raw data from file\n",
    "    # [Warning] 1st Column = date, 2nd Column = value\n",
    "    airkorea_pm25 = pd.read_excel(filepath, header=None, sheet_name='실외 초미세먼지 농도', parse_dates=[0])\n",
    "    airkorea_pm25.columns = ['date', 'airkorea_pm25']\n",
    "    auton_incabin_pm25 = pd.read_excel(filepath, header=None, sheet_name='차량내 초미세먼지 농도', parse_dates=[0])\n",
    "    auton_incabin_pm25.columns = ['date', 'auton_incabin_pm25']\n",
    "\n",
    "    # 2. date merge\n",
    "    aligned_pm25 = pd.merge_asof(auton_incabin_pm25, airkorea_pm25, on=['date'])\n",
    "    \n",
    "    # 3. return raw data (without preprocessing)\n",
    "    return aligned_pm25\n",
    "\n",
    "'''\n",
    "Preprocessing\n",
    "'''\n",
    "def preprocess(aligned_data:pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # 1. zero to NaN\n",
    "    aligned_data[\"airkorea_pm25\"] = aligned_data[\"airkorea_pm25\"].replace(0,np.NaN)\n",
    "\n",
    "    # 2. Z-score Normalization\n",
    "    aligned_data[\"airkorea_pm25_z\"] = stats.zscore(aligned_data[\"airkorea_pm25\"].dropna())\n",
    "\n",
    "    # 3. LOWESS Filtering\n",
    "    _lowess_fraction = 0.01 # 1% data will be used for local regression\n",
    "    airkorea_filtered = lowess(aligned_data[\"airkorea_pm25_z\"].values, aligned_data[\"airkorea_pm25_z\"].index.values, frac=_lowess_fraction)\n",
    "    index, data = np.transpose(airkorea_filtered)\n",
    "    aligned_data[\"airkorea_pm25_z_filtered\"] = pd.Series(data, index=index.astype(int))\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # 1. load data\n",
    "    data = loaddata_from_file(filepath=\"./data/44_2022-3-1_2022-3-31.xlsx\")\n",
    "    preprocess(data)\n",
    "\n",
    "    # 2. estimate from data\n",
    "    model = filterRUL(life=1000000, model='knn_outcabin')\n",
    "    result = model.estimate(data, '2022-03-01', '2022-04-01')\n",
    "    print(\"RUL Indication : {}% ({}/{})\".format(result[\"rul\"]/result[\"max_life\"]*100, result[\"rul\"],result[\"max_life\"]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "503028426f71a4cfa6a5c66878f050e899a10fc52c6ec1bb43435e00154d6959"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
